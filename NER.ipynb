{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siJMDMYge-7r",
        "outputId": "ed243528-07fe-4652-9ee7-b75c232ae04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")\n",
        "sys.path.append(\"/content/drive/My Drive/Colab Notebooks\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def fetch_news_article(api_key):\n",
        "    url = f'https://newsapi.org/v2/top-headlines?country=us&apiKey={api_key}'\n",
        "    response = requests.get(url)\n",
        "    articles = response.json()['articles']\n",
        "    if articles:\n",
        "        title = articles[0]['title'] or \"\"\n",
        "        description = articles[0]['description'] or \"\"\n",
        "        content = articles[0]['content'] or \"\"\n",
        "        return title + \"\\n\" + description + \"\\n\" + content\n",
        "    return None\n",
        "\n",
        "# Replace 'your_api_key_here' with your actual News API key\n",
        "news_article = fetch_news_article('55d7aa390e9a47ca92efe7985669b23e')\n",
        "print(news_article)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFyWt2rHfrqt",
        "outputId": "4852b502-7df7-43a1-c159-6aa79acfa422"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giants' Blake Snell throws first no-hitter of career vs. Reds - The New York Times\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "# Download necessary NLTK models\n",
        "nltk.download('punkt')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')  # Download the missing resource\n",
        "\n",
        "def nltk_ner(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    ne_tree = ne_chunk(pos_tags, binary=False)\n",
        "    named_entities = []\n",
        "\n",
        "    for subtree in ne_tree:\n",
        "        if isinstance(subtree, nltk.Tree):\n",
        "            entity_name = \" \".join([leaf[0] for leaf in subtree.leaves()])\n",
        "            entity_type = subtree.label()\n",
        "            named_entities.append((entity_name, entity_type))\n",
        "    return named_entities\n",
        "\n",
        "# Example usage\n",
        "news_article = \"\"\"Apple is looking at buying U.K. startup for $1 billion\"\"\"\n",
        "nltk_entities = nltk_ner(news_article)\n",
        "print(\"Entities extracted by NLTK:\", nltk_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hk_HshlhBZa",
        "outputId": "26d73e9b-3f49-4aa1-b6b7-c1c5b4b807b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities extracted by NLTK: [('Apple', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def spacy_ner(text):\n",
        "    doc = nlp(text)\n",
        "    named_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return named_entities\n",
        "\n",
        "spacy_entities = spacy_ner(news_article)\n",
        "print(\"Entities extracted by spaCy:\", spacy_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxAJHoKjhXqe",
        "outputId": "769a78eb-ad02-426d-d541-3e9bd6ee2095"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities extracted by spaCy: [('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_entities(nltk_entities, spacy_entities):\n",
        "    print(\"Comparison of entities extracted by NLTK and spaCy:\\n\")\n",
        "\n",
        "    print(\"Entities by NLTK:\")\n",
        "    for entity in nltk_entities:\n",
        "        print(entity)\n",
        "\n",
        "    print(\"\\nEntities by spaCy:\")\n",
        "    for entity in spacy_entities:\n",
        "        print(entity)\n",
        "\n",
        "    nltk_set = set(nltk_entities)\n",
        "    spacy_set = set(spacy_entities)\n",
        "\n",
        "    common_entities = nltk_set & spacy_set\n",
        "    nltk_only = nltk_set - spacy_set\n",
        "    spacy_only = spacy_set - nltk_set\n",
        "\n",
        "    print(\"\\nCommon Entities:\")\n",
        "    for entity in common_entities:\n",
        "        print(entity)\n",
        "\n",
        "    print(\"\\nEntities only by NLTK:\")\n",
        "    for entity in nltk_only:\n",
        "        print(entity)\n",
        "\n",
        "    print(\"\\nEntities only by spaCy:\")\n",
        "    for entity in spacy_only:\n",
        "        print(entity)\n",
        "\n",
        "compare_entities(nltk_entities, spacy_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U48jNKIAhgaG",
        "outputId": "1fc04217-2eb7-408c-b220-197eb2f31779"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of entities extracted by NLTK and spaCy:\n",
            "\n",
            "Entities by NLTK:\n",
            "('Apple', 'GPE')\n",
            "\n",
            "Entities by spaCy:\n",
            "('Apple', 'ORG')\n",
            "('U.K.', 'GPE')\n",
            "('$1 billion', 'MONEY')\n",
            "\n",
            "Common Entities:\n",
            "\n",
            "Entities only by NLTK:\n",
            "('Apple', 'GPE')\n",
            "\n",
            "Entities only by spaCy:\n",
            "('Apple', 'ORG')\n",
            "('U.K.', 'GPE')\n",
            "('$1 billion', 'MONEY')\n"
          ]
        }
      ]
    }
  ]
}